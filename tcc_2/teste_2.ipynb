{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Cross validate\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Modelos\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>Site</th>\n",
       "      <th>noticia_falsa</th>\n",
       "      <th>corpo_texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Universidade Yale publicou estudo ontem dá hid...</td>\n",
       "      <td>https://www.boatos.org/saude/universidade-yale...</td>\n",
       "      <td>10/10/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>sair … o esperar meta-análise chegar o trabalh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Empresa mídia interrompe impressão jornais Aus...</td>\n",
       "      <td>https://noticias.uol.com.br/internacional/ulti...</td>\n",
       "      <td>14/04/2020 09h53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>responsável jornal impresso comunitário o aust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enfermeiro mata namorada médica acusá-la passa...</td>\n",
       "      <td>https://noticias.uol.com.br/internacional/ulti...</td>\n",
       "      <td>02/04/2020 09h34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>o italiano antonio pace assumir matar o namora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vacinação viajantes</td>\n",
       "      <td>https://www.gov.br/saude/pt-br/vacinacao/viaja...</td>\n",
       "      <td>Data não disponível</td>\n",
       "      <td>Gov - Fake</td>\n",
       "      <td>0</td>\n",
       "      <td>['erro', 'carregar', 'texto']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Contágio classes C D São Paulo 5 vezes maior A B</td>\n",
       "      <td>https://noticias.uol.com.br/saude/ultimas-noti...</td>\n",
       "      <td>17/09/2020 12h25Atualizada em 17/09/2020 17h19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>paulistano classe c e d riscar infecção corona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5140</th>\n",
       "      <td>Ministro Saúde visita hospitais Manaus</td>\n",
       "      <td>https://www.gov.br/saude/pt-br/assuntos/notici...</td>\n",
       "      <td>04/05/2020 23h37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>n segunda-feira profissional saudar contratar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5141</th>\n",
       "      <td>'Estamos exaustos': efeito quarentena longa mu...</td>\n",
       "      <td>https://noticias.uol.com.br/ultimas-noticias/b...</td>\n",
       "      <td>24/08/2020 13h44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>argentino o chamar quareterna piar o isolament...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5142</th>\n",
       "      <td>vigilância coberturas vacinação: metodologia d...</td>\n",
       "      <td>https://www.gov.br/saude/pt-br/vacinacao/publi...</td>\n",
       "      <td>Data não disponível</td>\n",
       "      <td>gov.br saude</td>\n",
       "      <td>1</td>\n",
       "      <td>['vigilância', 'coberturas', 'vacinação', 'met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5143</th>\n",
       "      <td>Indígenas marcham defesa líder Yaku Pérez Equador</td>\n",
       "      <td>https://noticias.uol.com.br/ultimas-noticias/a...</td>\n",
       "      <td>11/02/2021 17h17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>indígena equatoriano mobilizar n quinta-feira ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5144</th>\n",
       "      <td>Testes positivos covid-19 SP atingem índice au...</td>\n",
       "      <td>https://noticias.uol.com.br/saude/ultimas-noti...</td>\n",
       "      <td>03/12/2020 04h00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>haver cercar semana laboratório e farmácia cre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5145 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     Universidade Yale publicou estudo ontem dá hid...   \n",
       "1     Empresa mídia interrompe impressão jornais Aus...   \n",
       "2     Enfermeiro mata namorada médica acusá-la passa...   \n",
       "3                                   vacinação viajantes   \n",
       "4      Contágio classes C D São Paulo 5 vezes maior A B   \n",
       "...                                                 ...   \n",
       "5140             Ministro Saúde visita hospitais Manaus   \n",
       "5141  'Estamos exaustos': efeito quarentena longa mu...   \n",
       "5142  vigilância coberturas vacinação: metodologia d...   \n",
       "5143  Indígenas marcham defesa líder Yaku Pérez Equador   \n",
       "5144  Testes positivos covid-19 SP atingem índice au...   \n",
       "\n",
       "                                                   link  \\\n",
       "0     https://www.boatos.org/saude/universidade-yale...   \n",
       "1     https://noticias.uol.com.br/internacional/ulti...   \n",
       "2     https://noticias.uol.com.br/internacional/ulti...   \n",
       "3     https://www.gov.br/saude/pt-br/vacinacao/viaja...   \n",
       "4     https://noticias.uol.com.br/saude/ultimas-noti...   \n",
       "...                                                 ...   \n",
       "5140  https://www.gov.br/saude/pt-br/assuntos/notici...   \n",
       "5141  https://noticias.uol.com.br/ultimas-noticias/b...   \n",
       "5142  https://www.gov.br/saude/pt-br/vacinacao/publi...   \n",
       "5143  https://noticias.uol.com.br/ultimas-noticias/a...   \n",
       "5144  https://noticias.uol.com.br/saude/ultimas-noti...   \n",
       "\n",
       "                                                 date          Site  \\\n",
       "0                                          10/10/2020           NaN   \n",
       "1                                   14/04/2020 09h53            NaN   \n",
       "2                                   02/04/2020 09h34            NaN   \n",
       "3                                 Data não disponível    Gov - Fake   \n",
       "4     17/09/2020 12h25Atualizada em 17/09/2020 17h19            NaN   \n",
       "...                                               ...           ...   \n",
       "5140                                 04/05/2020 23h37           NaN   \n",
       "5141                                24/08/2020 13h44            NaN   \n",
       "5142                              Data não disponível  gov.br saude   \n",
       "5143                                11/02/2021 17h17            NaN   \n",
       "5144                                03/12/2020 04h00            NaN   \n",
       "\n",
       "      noticia_falsa                                        corpo_texto  \n",
       "0                 0  sair … o esperar meta-análise chegar o trabalh...  \n",
       "1                 1  responsável jornal impresso comunitário o aust...  \n",
       "2                 1  o italiano antonio pace assumir matar o namora...  \n",
       "3                 0                      ['erro', 'carregar', 'texto']  \n",
       "4                 1  paulistano classe c e d riscar infecção corona...  \n",
       "...             ...                                                ...  \n",
       "5140              1  n segunda-feira profissional saudar contratar ...  \n",
       "5141              1  argentino o chamar quareterna piar o isolament...  \n",
       "5142              1  ['vigilância', 'coberturas', 'vacinação', 'met...  \n",
       "5143              1  indígena equatoriano mobilizar n quinta-feira ...  \n",
       "5144              1  haver cercar semana laboratório e farmácia cre...  \n",
       "\n",
       "[5145 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importação do Dataframe contendo títulos de notícias relacionadas a saúde.\n",
    "\n",
    "dataframe = pd.read_csv('combined_df.zip')\n",
    "\n",
    "display(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria dataframe para processamento\n",
    "df = dataframe.copy()\n",
    "\n",
    "# Transformar a coluna título em string\n",
    "df['title'] = df['title'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis para padronização/configuração\n",
    "\n",
    "scores = ['accuracy', 'precision', 'roc_auc']\n",
    "usar_links = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    True\n",
      "1    True\n",
      "2    True\n",
      "3    True\n",
      "4    True\n",
      "Name: title, dtype: bool\n",
      "Há documentos vazios? False\n",
      "Há links vazios? False\n",
      "Número de documentos vazios: 0\n",
      "Número de links vazios: 0\n"
     ]
    }
   ],
   "source": [
    "# Checar se há títulos vazios\n",
    "non_empty_titles = df['title'].apply(lambda x: len(x.strip()) > 0)\n",
    "non_empty_links = df['link'].apply(lambda x: len(x.strip()) > 0)\n",
    "\n",
    "# Checar o resultado\n",
    "print(non_empty_titles.head())\n",
    "print(\"Há documentos vazios?\", not non_empty_titles.all())\n",
    "print(\"Há links vazios?\", not non_empty_links.all())\n",
    "print(\"Número de documentos vazios:\", (~non_empty_titles).sum())\n",
    "print(\"Número de links vazios:\", (~non_empty_links).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF aplicado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Iniciar o processo de TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Nesta célula, será aplicado o TF-IDF aos títulos das notícias, caso não haja nenhum vazio\n",
    "temp_tit = df['title'].tolist()\n",
    "if non_empty_titles.all():\n",
    "    titles_tfidf = tfidf_vectorizer.fit_transform(temp_tit)\n",
    "    print('TF-IDF aplicado com sucesso.')\n",
    "    tfidf = titles_tfidf\n",
    "else:\n",
    "    print('Há documentos vazios ou apenas stop words.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF aplicado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "if usar_links:\n",
    "    # Tratando os links\n",
    "    def split_and_clean(link):\n",
    "    # Dividir o link por '/', '-', '%', '.', e ':'\n",
    "        words = re.split(r'[/\\-\\%\\.\\:\\_]', link)\n",
    "        # Remover palavras indesejadas, stopwords e letras isoladas, mantendo acentos\n",
    "        unwanted = {'https', 'www', 'com', 'br', 'pt', 'html', 'htm', 'ghtml'}\n",
    "        cleaned_words = [\n",
    "        word for word in words\n",
    "        if not any(unwanted_word in word.lower() for unwanted_word in unwanted)\n",
    "        and len(word) > 1\n",
    "        ]\n",
    "        return cleaned_words\n",
    "\n",
    "    df['processed_links'] = df['link'].apply(split_and_clean)\n",
    "\n",
    "    # TF-IDF para os combinação título e link\n",
    "    temp_link = [' '.join(i) for i in df['processed_links']]\n",
    "    temp_tit_link = [' '.join(list(a)) for a in zip(temp_tit, temp_link)]\n",
    "    if non_empty_links.all():\n",
    "        tit_link_tfidf = tfidf_vectorizer.fit_transform(temp_tit_link)\n",
    "        print('TF-IDF aplicado com sucesso.')\n",
    "        tfidf = tit_link_tfidf\n",
    "    else:\n",
    "        print('Há items vazios ou apenas stop words.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões de X: (5145, 11083)\n",
      "Dimensões de y: (5145,)\n"
     ]
    }
   ],
   "source": [
    "# Criação de vetores\n",
    "X = tfidf\n",
    "y = df['noticia_falsa']\n",
    "\n",
    "titulos = df['title'].tolist()\n",
    "\n",
    "print(\"Dimensões de X:\", X.shape)\n",
    "print(\"Dimensões de y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de Classificação\n",
    "### Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padronizando scores para todos os modelos.\n",
    "\n",
    "scores = ['accuracy', 'precision', 'roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.975\n",
      "Precisão: 0.982\n",
      "ROC-AUC: 0.970\n"
     ]
    }
   ],
   "source": [
    "# Cria modelo\n",
    "modelo_ad = DecisionTreeClassifier()\n",
    "modelo_ad\n",
    "\n",
    "# Validação crucru\n",
    "resultados_ad = cross_validate(modelo_ad, X, y, scoring=scores)\n",
    "\n",
    "acc_ad = resultados_ad['test_accuracy'].mean()\n",
    "prec_ad = resultados_ad['test_precision'].mean()\n",
    "rocauc_ad = resultados_ad['test_roc_auc'].mean()\n",
    "print(f'Acurácia: {acc_ad:.3f}\\nPrecisão: {prec_ad:.3f}\\nROC-AUC: {rocauc_ad:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floresta Aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.977\n",
      "Precisão: 0.975\n",
      "ROC-AUC: 0.992\n"
     ]
    }
   ],
   "source": [
    "# Cria modelo\n",
    "modelo_rf = RandomForestClassifier()\n",
    "modelo_rf\n",
    "\n",
    "# Validação crucru\n",
    "resultados_rf = cross_validate(modelo_rf, X, y, scoring=scores)\n",
    "\n",
    "acc_rf = resultados_rf['test_accuracy'].mean()\n",
    "prec_rf = resultados_rf['test_precision'].mean()\n",
    "rocauc_rf = resultados_rf['test_roc_auc'].mean()\n",
    "print(f'Acurácia: {acc_rf:.3f}\\nPrecisão: {prec_rf:.3f}\\nROC-AUC: {rocauc_rf:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.973\n",
      "Precisão: 0.967\n",
      "ROC-AUC: 0.988\n"
     ]
    }
   ],
   "source": [
    "# Cria modelo\n",
    "modelo_lr = LogisticRegression()\n",
    "modelo_lr\n",
    "\n",
    "# Validação crucru\n",
    "resultados_lr = cross_validate(modelo_lr, X, y, scoring=scores)\n",
    "\n",
    "acc_lr = resultados_lr['test_accuracy'].mean()\n",
    "prec_lr = resultados_lr['test_precision'].mean()\n",
    "rocauc_lr = resultados_lr['test_roc_auc'].mean()\n",
    "print(f'Acurácia: {acc_lr:.3f}\\nPrecisão: {prec_lr:.3f}\\nROC-AUC: {rocauc_lr:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.982\n",
      "Precisão: 0.980\n",
      "ROC-AUC: 0.987\n"
     ]
    }
   ],
   "source": [
    "# Parâmetros\n",
    "C = 77\n",
    "kernel = 'rbf'\n",
    "gamma = 0.01\n",
    "\n",
    "# Cria modelo\n",
    "modelo_svm = svm.SVC(C=C, kernel=kernel, gamma=gamma)\n",
    "\n",
    "# Validação crucru\n",
    "resultados_svm = cross_validate(modelo_svm, X, y, scoring=scores)\n",
    "\n",
    "acc_svm = resultados_svm['test_accuracy'].mean()\n",
    "prec_svm = resultados_svm['test_precision'].mean()\n",
    "rocauc_svm = resultados_svm['test_roc_auc'].mean()\n",
    "print(f'Acurácia: {acc_svm:.3f}\\nPrecisão: {prec_svm:.3f}\\nROC-AUC: {rocauc_svm:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predição teste com dados externos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Vacinas contra a Covid-19 são mais perigosas q...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Vacina tem como objetivo matar seres humanos</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Profissionais de saúde morrem por ataque cardí...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Butantan não confirma eficácia da CoronaVac em...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vacinas de RNA mensageiro vão provocar morte e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>A vacina contra a Covid-19 vai modificar o DNA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>A vacina contra a Covid-19 tem chip líquido e ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Imunizantes contra Covid-19 estão relacionados...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Vacinas contra Covid-19 criam campo magnético ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>CoronaVac não tem comprovação científica</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Pandemia acentuou queda de vacinação no Brasil</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Brasil tem mais baixa cobertura da vacina tríp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Maioria dos municípios brasileiros não atingiu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Brasil avança na imunização e sai da lista dos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Brasil recebe primeiro lote de vacinas atualiz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>A vacinação infantil contra covid-19 oferecida...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>O Brasil não é o único país a exigir vacinação...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Vacina nacional contra covid está em fase avan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Em 2023, 88,2% das pessoas de 5 anos ou mais h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Vacinas contra a Covid-19 não tem relação com ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0                                                  1  2\n",
       "0    1  Vacinas contra a Covid-19 são mais perigosas q...  0\n",
       "1    2       Vacina tem como objetivo matar seres humanos  0\n",
       "2    3  Profissionais de saúde morrem por ataque cardí...  0\n",
       "3    4  Butantan não confirma eficácia da CoronaVac em...  0\n",
       "4    5  Vacinas de RNA mensageiro vão provocar morte e...  0\n",
       "5    6  A vacina contra a Covid-19 vai modificar o DNA...  0\n",
       "6    7  A vacina contra a Covid-19 tem chip líquido e ...  0\n",
       "7    8  Imunizantes contra Covid-19 estão relacionados...  0\n",
       "8    9  Vacinas contra Covid-19 criam campo magnético ...  0\n",
       "9   10           CoronaVac não tem comprovação científica  0\n",
       "10  11     Pandemia acentuou queda de vacinação no Brasil  1\n",
       "11  12  Brasil tem mais baixa cobertura da vacina tríp...  1\n",
       "12  13  Maioria dos municípios brasileiros não atingiu...  1\n",
       "13  14  Brasil avança na imunização e sai da lista dos...  1\n",
       "14  15  Brasil recebe primeiro lote de vacinas atualiz...  1\n",
       "15  16  A vacinação infantil contra covid-19 oferecida...  1\n",
       "16  17  O Brasil não é o único país a exigir vacinação...  1\n",
       "17  18  Vacina nacional contra covid está em fase avan...  1\n",
       "18  19  Em 2023, 88,2% das pessoas de 5 anos ou mais h...  1\n",
       "19  20  Vacinas contra a Covid-19 não tem relação com ...  1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_externo = pd.read_csv('Notícias Fake e Verdadeiras.txt', header=None, sep='\\t', on_bad_lines='skip')\n",
    "df_externo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define modelos para teste\n",
    "modelos = [modelo_ad, modelo_rf, modelo_lr, modelo_svm]\n",
    "\n",
    "# Função para predizer novos títulos\n",
    "def predict_title(titulo):\n",
    "    preprocessed_title = titulo.srt.lower()\n",
    "    preprocessed_title = nltk.sent_tokenize(titulo)\n",
    "    preprocessed_title = nltk.word_tokenize(titulo)\n",
    "\n",
    "    preprocessed_title_text = ' '.join(preprocessed_title)\n",
    "\n",
    "    tfidf_vector = tfidf_vectorizer.transform([' '.join(preprocessed_title_text)])\n",
    "\n",
    "    for modelo in modelos:\n",
    "        predicao = modelo.predict(tfidf_vector)\n",
    "\n",
    "    return predicao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'noticias_combinedtrue.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m true_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mnoticias_combinedtrue.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m false_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mnoticias_combinedfake.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39m#Remover maiúsculas\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'noticias_combinedtrue.csv'"
     ]
    }
   ],
   "source": [
    "# true_df = pd.read_csv('noticias_combinedtrue.csv')\n",
    "# false_df = pd.read_csv('noticias_combinedfake.csv')\n",
    "\n",
    "# #Remover maiúsculas\n",
    "# true_df['corpo_texto'] = true_df['corpo_texto'].str.lower()\n",
    "# true_df['title'] = true_df['title'].str.lower()\n",
    "# true_df['corpo_texto'] = true_df['corpo_texto'].apply(nltk.word_tokenize)\n",
    "# #true_df['title'] = true_df['title'].apply(nltk.word_tokenize)\n",
    "\n",
    "# false_df['corpo_texto'] = false_df['corpo_texto'].str.lower()\n",
    "# false_df['title'] = false_df['title'].str.lower()\n",
    "# false_df['corpo_texto'] = false_df['corpo_texto'].apply(nltk.word_tokenize)\n",
    "# #false_df['title'] = false_df['title'].apply(nltk.word_tokenize)\n",
    "\n",
    "# stop_words = set(stopwords.words('portuguese'))\n",
    "\n",
    "# #função para remover pontuação\n",
    "# def clean_text(tokens):\n",
    "#     return [re.sub(r'[^\\w\\s]', '', word) for word in tokens if word not in stop_words and re.sub(r'[^\\w\\s]', '', word)]\n",
    "\n",
    "# #Remover stop_words\n",
    "\n",
    "# true_df['corpo_texto'] = true_df['corpo_texto'].apply(clean_text)\n",
    "# false_df['corpo_texto'] = false_df['corpo_texto'].apply(clean_text)\n",
    "# #true_df['title'] = true_df['title'].apply(clean_text)\n",
    "# #false_df['title'] = false_df['title'].apply(clean_text)\n",
    "\n",
    "# display(true_df, false_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
